\chapter{Custom Framework}

This chapter aims to present the custom framework that was developed
within the course of this thesis. This framework is based upon CACE
ZKC framework with our custom additions added. Figure
\ref{fig:custom_framework_workflow} gives an overview of our
extensions which will be presented in Section
\ref{sec:cace_extensions} with the implementation details coming at
the end of the chapter.

The chapter starts with presenting our motivation for a custom
framework from two separate sides:
\begin{itemize}
\item The very need for such frameworks where we defend domain
  specific languages as viable alternatives to general purpose
  programming languages
\item The need for cheap, embedded hardware realizations of such
  complex protocols. It is here that we have observed limitations in
  the CACE ZKC framework that we will try to alleviate using our
  extensions
\end{itemize}
We will target two separated extremes of the HW-SW co-design spectrum
and as such provide two back-ends (a purely software one in C using
GMP and a purely hardware one in GEZEL).  To make the GEZEL Back-end
functional we needed to extend the GEZEL language (see Sub-section
\ref{subsec:gezel}) to allow new operators and interactive
communication with the host the simulation is running on. These GEZEL
extensions are covered in Section \ref{sec:gezel_extensions}.

We conclude the chapter by presenting the flow of the custom framework
from the front-end to the back-end in a sequential manner, the way it
processes the input files given to it.

\begin{figure}[hb!]
  \centering
  \begin{tikzpicture}[>=stealth,level distance=1.5cm, font=\tiny]
    \tikzstyle{edge from parent}=[draw,->] \tikzset{every leaf
      node/.style={anchor=center}}

    \Tree [.\node[language](psl){Protocol \\ Specification \\ Language (PSL)};
      [.\node[compiler](pc){Protocol \\ Compiler};
        [.\node[language](pil){Protocol \\ Implementation \\ Language (PIL)};
          [.\node[compiler,added](llvm){LLVM};
            \node[language,added](asm){x86 \\ x86-64 \\ MIPS \\ARM};
            \node[language,added](gezel){GEZEL \\ VHDL \\ Verilog};
          ]
          [.\node[compiler](c){C}; \node[language](code){Code};]
          [.\node[compiler](latex){\LaTeX}; \node[language](doc){Documentation};]
        ]
      ]
    ]

    \node[compiler] (pvt)         [right=of pc,anchor=west]          {Protocol \\ Verification \\ Toolbox}
    child {node[language] {Proof of \\ Soundness}};

    \node[compiler] (sigma) [left=of pil.north west,anchor=center] {$\Sigma 2 N I Z K$};
    \node[compiler] (cost) [left=of pil.south west,anchor=center] {Costs};

    \draw[<->] (sigma) -- (pil);
    \draw[<->] (cost) -- (pil);

    \draw[->] (psl) -- (pvt);
    \draw[->] (pil) -- (pvt);
  \end{tikzpicture}
  \caption{Custom framework (extensions to CACE Zero Knowledge
    Compiler highlighted)}
  \label{fig:custom_framework_workflow}
\end{figure}

\section{Motivation}

\subsection{Domain Specific Languages}

A domain specific language is a language specifically tailored for a
target application. It hides all the operations that are deemed not
important and allows an abstract overview of the operations. As such,
it is directly contrasted with general purpose programming languages
like C.

Also, C is not a very safe language for cryptography applications as
can be seen from the designer's goal of C to design a ``portable''
assembler. The design choice was favoring speed and efficiency over
strict definitions and specifications so some things are left
undefined or unspecified. It is left to the end compilers to implement
it as they choose with the usual choice just implementing it in the
most efficient way for the target platform. For example, the following
code demonstrates this unspecified behavior:

\begin{lstlisting}[language=C]
#include <stdio.h>

int b(void) { puts("3"); return 3; }
int c(void) { puts("4"); return 4; }

int main(void)
{
  int a = b() + c();
  printf("%d\n", a);

  return 0;
}
\end{lstlisting}

The evaluation order is unspecified so depending on the compiler and
the platform, the output may be 3, 4, 7 or 4, 3, 7. The cryptography
world should not have neither undefined nor unspecified behaviors and
for this a domain specific language is a key point of this thesis.

Similar logic can be applied to other general purpose programming
languages as well. Either they add complexity or make trade-offs not
suitable for the field of cryptography. As such, the approach of
current Zero Knowledge Proof of Knowledge frameworks is to define
their own domain-specific language and we will follow suit by basing
ours on PIL (see Sub-section \ref{subsec:pil}).

\subsection{CACE Zero Knowledge Compiler Limitations}

CACE ZKC supports only C as an implementation target, using GMP (see
Sub-section \ref{subsec:gmp}) as its multi-precision library. We
perceive limitations with this approach w.r.t to small, embedded
devices.

The generality coming from C and GMP incurs a penalty. For example, GMP
requires two steps to perform a modular multiplication, namely
multiplication and a reduction step. The multiplication step will
incur a performance loss since 2 n-bit operands produce a 2n-bit
result when multiplied, and the additional memory needs to be
allocated and de-allocated. Also, by transforming a modular
multiplication into 2 steps, the information that it was a modular
multiplication is lost and has to be re-generated. This complicates
optimization as well as formal verification.

The tight coupling of the main code and the supporting library limit
HW-SW co-design. The CACE generated code expects a supporting library
to conform to a specific interface. This limits the co-design to only
coarsely-grained since it does not allow exposing of the internals of
the operations supported.

\subsection{LLVM IR}

The LLVM intermediate form, LLVM IR, is of the SSA (Static Single
Assignment) form (see Sub-section \ref{subsec:llvm}), allowing easier
DFG extraction. More aggressive optimizations are possible this way as
it is possible to see the usage of all the intermediate results. Also,
the extracted DFG allows us to generate a corresponding CFG for a
hardware realization. We can also support multiple execution modes as
LLVM already allows for:
\begin{itemize}
\item Interpreted code - by using its interpreter
\item JIT (Just In Time) compiled code - by compiling the code at runtime
\item Compiled code - by allowing to code to be compiled later on
\end{itemize}

\section{Extensions to CACE Zero Knowledge Compiler}
\label{sec:cace_extensions}

\subsection{Terminal Functionality}

Although we extended CACE from outside, leaving its internals intact,
it was decided to add terminal functionality to the core. This allowed
us to add serial communication support and to cross-check the
implementations generated by our framework with the CACE
implementations. Serial communication is simpler as it can be
implemented over an RS232 communication protocol and it will be the
default communication of our framework.

\subsection{Lower Level}

An overview of the extensions to the CACE ZKC framework was already
presented in Figure \ref{fig:custom_framework_workflow} and is
detailed in Figure \ref{fig:custom_llvm_workflow}. The input file is
processed by a PIL front-end which generates LLVM IR code. Optimization
passes are performed on this IR before finally transforming it to
desired targets via suitable back-ends.

\begin{figure}[hb!]
  \centering
  \begin{tikzpicture}[>=stealth]
    \tikzstyle{lang}=[rectangle,draw=black,thin,font=\tiny,inner
    sep=0pt, align=center,minimum width=2cm,minimum height=2.3em]

    \tikzstyle{txt}=[font=\tiny]

    \node[lang](llvm_opt){LLVM \\ Optimizer};

    \node[lang,added](gmp_back)[right=1 cm of llvm_opt]{Custom \\ GMP Backend};
    \node[txt](gmp)[right=of gmp_back]{C+GMP code};

    \node[lang,added](gezel_back)[below=of gmp_back]{Custom \\ GEZEL Backend};
    \node[txt](gezel)[right=of gezel_back]{GEZEL};

    \node[lang,added](llvm_pass)[below=1 cm of llvm_opt]{Optimization \\ Passes};

    \node[lang,added](pil_front)[left=1 cm of llvm_opt]{PIL \\ Frontend};
    \node[txt](pil)[left=of pil_front]{PIL};

    \draw[->] (pil_front.east) -- (llvm_opt.west);

    \draw[->] (pil) -- (pil_front);

    \draw[->] (llvm_opt.east) -- (gezel_back.west);
    \draw[->] (llvm_opt.east) -- (gmp_back.west);

    \draw[->] (gezel_back) -- (gezel);
    \draw[->] (gmp_back) -- (gmp);

    \draw[<->] (llvm_opt) -- (llvm_pass);
  \end{tikzpicture}
  \caption{LLVM custom workflow (changes highlighted)}
  \label{fig:custom_llvm_workflow}
\end{figure}

\subsubsection{Optimization Passes}

The compiler translates the input operation by operation and as such
necessarily generates sub-optimal code or code that requires a
non-trivial CFG. An example is when reading from and writing to global
variables because the compiler cannot know the general context of use
while translating a single store/load operation. Every access to a
global variable will produce a store when writing or a load when
reading and this clearly requires a non-trivial CFG since memory
operation impose an inherent ordering due to only one operation
allowed withing a single clock cycle.

\paragraph{Store/Load Pass}
The job of the Store/Load optimizer is to eliminate unnecessary
reading from the memory. In our model of computation we assume that
only the current round of the protocol is allowed to access the
memory. As such, all the values stored to the memory need not be read
from the memory again during the execution of the same round.

\subsubsection{Back-ends}

Two back-ends are provided targeting the two extremes of the HW-SW
co-design spectrum. A purely software implementation in C using GMP is
generated by the C+GMP back-end while a purely hardware implementation
is generated by the GEZEL back-end.

We believe that this is a good starting point as it shows the two
disjoint modes of operation, namely a non-trivial CFG generated in the
case of a software implementation and a trivial CFG in the case of a
hardware implementation. It is not difficult to make further
enhancements that will allow to explore the co-design spectrum in the
``middle''.

\subsubsection{Formal Verification}

CACE ZKC already offers a formal proof of correctness covering the
transformation from PSL to PIL, and ZKCrypt extends it with further
proofs (see Sub-section \ref{subsec:zkcrypt}. Our framework is
complementary and we need to analyze the security of the
transformation from PIL to LLVM IR and LLVM IR to the back-ends
whenever possible.

LLVM IR allows us to verify the correctness of the types since LLVM IR
uses code of the static single assignment form, where every variable
is assigned a value exactly once. This allows security assertions to
be taken to a lower level than the one allowed by CACE. To assure the
correctness of types, first it is necessary to lay out the DFG of the
protocol round. For each node of the DFG preconditions and
postconditions cab be established, such as the ones in Table
\ref{tab:basic_nodes}. Hoare logic~\cite{hoare_logic} can then be used
to prove the correctness of the transformation from PIL to the LLVM
IR.

As for the transformation of LLVM IR into target implementations, it
might not always be possible to prove correctness, especially if the
target implementation is a physical hardware realization. Since it was
impossible to make this assurance it was deemed unnecessary to go this
low and the blocks are assumed to be correct (if the preconditions are
satisfied, the postconditions will be assured by the block) which is
as low as we could go. For the software case, such properties are
assumed to be assured by the library used.

\begin{table}[h!]
  \centering
  \begin{tabular}{l | c | c}
    Operation              & Preconditions             & Postconditions \\
    \hline
    Modular addition       & $x \in Z_q^+, y \in Z_q^+$ & $z \in Z_q^+$ \\ 
    Modular multiplication & $x \in Z_p^*, y \in Z_p^*$ & $z \in Z_p^*$ \\
    Modular exponentiation & $x \in Z_p^*, y \in Z_p$   & $z \in Z_p^*$ \\
    Zero extension         & $x \in Z_p$               & $z \in Z_p$
  \end{tabular}
  \caption{Operation pre-conditions and post-conditions}
  \label{tab:basic_nodes}
\end{table}

\subsection{Extensions to PIL}
\label{subsec:pil_extensions}

\subsubsection{Multiple Blocks}

The base PIL language supported only a Prover and a Verifier block
besides the Common block. This makes it impossible to implement a
multiparty protocol\footnote{In the cryptographic world, this means
  three or more parties}. The grammar was re-written from scratch to
allow this change to be a simple relaxation of the grammar rules
\begin{lstlisting}[language=grammar, keywords={proof, execution_order, block}]
proof	:	execution_order (block)*
	;
\end{lstlisting}

\subsubsection{Compile Time/Constant Expressions}

Compile time/constant expressions were needed to allow more advanced
specifications of protocols. The PIL language does not specify
constant expressions as parameters of variables. When designing more
complex protocols where parameters of variables have to be adjusted,
one needs constant expressions. The benefit of constant expressions
can be seen from the following example:
\begin{lstlisting}[language=PIL]
Common (
  Z l_n = 1024;
  Z l_f = 160;
  Z l_e = 410;
  Z l_e_1 = 120;
  Z l_v = 1512;
  Z l_phi = 80;
  Z l_H = 160;
  Prime(l_n) n = 17
) {

}

Smartcard (
  Zmod*(n) p, q;
  Int(l_f + l_phi + l_H) f
) {
  Zmod*(n) S, _Z, R;
  Int(l_n + l_phi) v_1;
  Int(l_v) v;
  ...
\end{lstlisting}
Without constant expressions, one would need to recompute the values
manually and enter them every time a change was desired. This
re-computation and reentering is prone to errors and as such
undesirable when designing a crypto framework. The grammar change to
allow constant expressions is very simple
\begin{lstlisting}[language=grammar, keywords={group, expr}]
group	:	('Zmod+'|'Zmod*') '(' expr ')' 
	|	'Prime' '(' expr ')'
	|	'Int' '(' expr ')'
	|	'Z'
	;
\end{lstlisting}
This change allows it only syntactically so some semantic processing
will be needed to ensure that they are constant expressions which can
be evaluated at compile time by the compiler.

\subsubsection{Type Inference}

To be able to check for correctness, one needs to determine the resulting
type of a certain expression. This can be also used to allow one to omit
a type declaration. The following example illustrates this:
\begin{lstlisting}[language=PIL]
Zmod*(p) b;
x := Random(Int(80));
a := b^x;
\end{lstlisting}
For the case of variable x, its type can be inferred as Int(80) since
the Random function can only return a random value of the provided
type. For the case of variable a, the situation is a bit more
complex. However, if the operation of exponentiation is defined as
applying the multiplication operation many times, then the type of a
can only be Zmod*(p) by the definition of the multiplicative modular
residue group. A similar case can be made when multiplying an element
of the additive modular residue group with an integer. This means that
the type inference is well defined for any acceptable operation in
PIL.

\section{Extensions to GEZEL}
\label{sec:gezel_extensions}

We decided to modify GEZEL to allow communication with the simulation
host. This allows the simulated hardware within GEZEL to communicate
with other programs running on the host computer. Such a change
allowed us to cross-check the target implementations generated by our
framework with the implementations generated by the CACE ZKC.

Another change we have introduced is adding a modular exponentiation
operator. We acknowledge that GEZEL's expressiveness allows for such a
construct within the language itself, however, such a step would
require a lot of time and clearly was not a central point in this
thesis. We have, however, wrapped the operation execution within a
modular exponentiator block to allow such a block to be constructed
later.

\subsection{Terminal Communication ipblock}

Serial communication with the simulation host was realized by creating
an ipblock. This ipblock allows connecting to the host via
pseudo-terminals or to other devices via serial ports as shown in
Figure \ref{fig:gezel_ipblock}.

\begin{figure}[hb!]
  \centering
  \begin{tikzpicture}[>=stealth]
    \node(gezel){GEZEL};
    \node(ipblock)[left=of gezel]{ipblock};

    \draw[<->] (gezel) -- (ipblock);
  \end{tikzpicture}
  \caption{GEZEL and ipblock}
  \label{fig:gezel_ipblock}
\end{figure}

This ipblock was originally aimed to be connected to gplatform's 8051
simulator but the simulator core itself does not allow easy
connections of an external serial port. The decision was made to make
a transceiver ipblock that receives and transmits parsed numbers
making it easier to use within GEZEL.

\begin{lstlisting}[language=GEZEL]
ipblock my_term(in tx    : ns(1024);
                out rx   : ns(1024);
                in sr    : ns(2);
                out done : ns(1)) {
  iptype "transceiver";
}
\end{lstlisting}

Output to the ``outside'' world is given to the \emph{tx} pin (marked
here as in because the directions are relative to the ipblock). Input
from the ``outside'' world is taken from the \emph{rx} pin. The
``outside'' world denotes the process running outside of the
simulation that is connected via a terminal. The \emph{sr} specifies
the operation: $0$ for no operation, $1$ for sending, $2$ for
receiving. After the operation is done, the ipblock sets the
\emph{done} pin to $1$.

\subsection{Modular exponentiation}

Although GEZEL supports modular operations (addition, subtraction and
multiplication), it does so via two binary operations. First the normal
operation is performed and then the modular reduction. This may be
possible for addition, subtraction and multiplication where the
largest intermediate result is twice the size, but it is definitely
not possible for modular exponentiation where the intermediate size
grows exponentially. This, along with complex hardware realizations
were probably the main reasons for not having this already in GEZEL.

The modular exponentiation is not a central point in the thesis and,
as the exponentiation is much easier to realize in C++ code, the
decision was made to extend GEZEL. This required rewriting the
grammar, adding a new operation and adding run-time emitting of the
code for the exponentiation. The syntax of the modular exponentiation
operation is:
\begin{lstlisting}
y = g ** x % p;
\end{lstlisting}

The GMP library, for reasons of intermediate results growing
exponentially, supports only a modular exponentiation. This is a
ternary operation requiring a modulus as well. This required a
significant change in the GEZEL core but the advantages of a having a
well tested and working implementation of modular exponentiation
outweighed the disadvantages. To allow the modular exponentiation to
be later implemented purely in GEZEL, we have wrapped the operation in
a block:
\begin{lstlisting}[language=GEZEL]
dp modexp (in inx, iny : ns(1024);
           in modulus  : ns(1024);
           out output  : ns(1024)) {
  always {
    output = inx ** iny % modulus;
  }
}
\end{lstlisting}

\section{Front-end}
\label{sec:pil_frontend}

PIL frontend flow is depicted in Figure \ref{fig:pil_frontend_flow}.  An
input PIL is read by the Lexer producing input for the Parser. The
Parser reads these and generates an abstract syntax tree (AST) which
is fed to the Codegen tree-walker that generates the code (in the form
of LLVM IR).

\begin{figure}[hb!]
  \centering
  \subfloat{
  \begin{tikzpicture}[>=stealth]
    \tikzstyle{edge from parent}=[draw,->]

    \Tree[.\node[language](parser_g){pil.g};
      [.\node[compiler](antlr){ANTLR};
        [.\node[compiler](lexer){Lexer};]
        [.\node[compiler](parser){Parser};]
      ]
    ]
  \end{tikzpicture}
  } \qquad
  \subfloat{
  \begin{tikzpicture}[>=stealth]
    \tikzstyle{edge from parent}=[draw,->]

    \Tree[.\node[language](tree_g){codegen.g};
      [.\node[compiler](antlr2){ANTLR};
        [.\node[compiler](walker){Codegen};]
      ]
    ]
  \end{tikzpicture}
  }
  \caption{Lexer, parser and tree walker generation}
\end{figure}

\begin{figure}[hb!]  
  \begin{tikzpicture}[>=stealth]
    \node[language] (pil) {PIL};
    \node[compiler] (lexer) [right=of pil] {Lexer};
    \node[compiler] (parser) [right=of lexer] {Parser};
    \node[language] (ast) [right=of parser] {AST};
    \node[compiler] (codegen) [right=of ast] {Codegen};
    \node[language] (llvm_ir) [right=of codegen] {LLVM IR};

    \draw[->] (pil) -- (lexer);
    \draw[->] (lexer) -- (parser);
    \draw[->] (parser) -- (ast);
    \draw[->] (ast) -- (codegen);
    \draw[->] (codegen) -- (llvm_ir);
  \end{tikzpicture}
  \caption{PIL frontend flow}
  \label{fig:pil_frontend_flow}
\end{figure}

The code generation process generates one module per block. The Common
block module is augmented with the functions provided by the VM.
Every other block except the Common block gets a Common block linked
in. This process is depicted in Figure \ref{fig:linker}.

\begin{figure}[hb!]
  \centering
  \begin{tikzpicture}[>=stealth]
    \node[language] (block) {Block};
    \node[compiler] (linker) [right=of block] {Linker};
    \node[language] (common) [above=of linker] {Common};
    \node[language] (module) [right=of linker] {Module};

    \draw[->] (block) -- (linker);
    \draw[->] (common) -- (linker);
    \draw[->] (linker) -- (module);
  \end{tikzpicture}
  \caption{Linker}
  \label{fig:linker}
\end{figure}

The private parameters as well as global variables are transformed as
LLVM IR global variables, the private parameters being constant in
this case. Each function of a block gets transformed as an LLVM IR
function with its input and output arguments transformed as such. LLVM
allows for multiple return values so this is used as well when there
are multiple return values.

LLVM's constant folder is used to evaluate constant time expressions
to simplify them into a constant value.

When dealing with group arithmetic, which LLVM does not support, there are
two possibilities:
\begin{enumerate}
\item extend the LLVM's type system to include group types - this
  involves editing the core LLVM files, adding a new DerivedType,
  changing the bit-code format and adding changes to the LLVM parser
  (both binary and textual). Also, binary operations have to be redefined
  to support these new types \cite{extending_llvm}.
\item use a simpler, existing LLVM type and make the compiler do the
  extra work - the IntegerType of LLVM can be used for arbitrarily sized
  integers.
\end{enumerate}

The first option allows for preserving the information about the
modular residue groups to the lowest level. The transformation to a
primitive type supported by the target architecture happens only at a
later stage. Or, if the target architecture supports modular residue
groups, there is need for no transformation, only a translation.  This
allows for a code that is more verifiable and more secure as the
properties are kept to the lowest possible levels (no exploits can be
made under secure starting conditions). The disadvantage of this
method is the changes that need to be introduced at the heart of such
a complex framework as LLVM is. This is both time consuming and error
prone. Also, it becomes more difficult to track newer versions of LLVM
(with possibly better optimizations and more features) if the changes
are not integrated back into the main project. This method also breaks
compatibility with existing LLVM applications, so a specially patched
version of LLVM needs to be distributed.

The second option is easier as the changes to the compiler are only
local and do not break compatibility with existing LLVM applications.
It is also easier as there is no hard work associated with changing
the core of LLVM. More work has to be assigned to the compiler because
it needs to track types and apply the appropriate operations in the
case of modular residue groups. The burden is also on the back-end if
an architecture supports modular residue groups since it now has to
regenerate the lost information. An example of such an architecture
can be an automatic verifier whose job is now made more complex. This
re-generation of information might also not be always completely
accurate.

The first approach was attempted first but was deemed too time
consuming and error prone. Also it would require some standardization
with LLVM upstream to allow future tracking. The second approach was
chosen as the one to base the work on. The types are backed by an
IntegerType of the appropriate length in the LLVM IR. Type inference
was used to deduce the resulting type of an operation. The operation
was then sent to appropriate 3 argument operations with the first 2
being the operands as integers and the third operand being the
modulus.

\subsection{Type Alias}

Type aliases are evaluated and substituted by the parser. The
reasoning behind them can go both ways. Although they are more
semantic than syntactic since they convey information (as a creation
of another type), they are simple enough to be evaluated and
substituted by the parser. This can be paralleled with a pre-processor
in languages which support it. The rule includes a syntactic predicate
to test if it is a declaration of an alias or an alias is referenced.
\begin{lstlisting}[language=C++, keywords={ID, group, interval, alias}]
alias :
      (ID '=' )=> ID! '='! (
        group { aliases[(const char*)$ID.text->chars] = $group.tree; } 
      | interval { aliases[(const char*)$ID.text->chars] = $interval.tree; }
      )
      |	ID -> { aliases[(const char*)$ID.text->chars] }
      ;
\end{lstlisting}
If the syntactic predicate matches, the alias is stored in a hashmap,
otherwise the hashmap is searched for the alias. This syntactic
predicate effectively implements a 1 symbol look-ahead.

\subsection{Type system}

The compiler has to keep track of the types. A simple type system was
designed that allows both numbers and modular residues. The UML of
this type system is given in Figure \ref{fig:type_system}.

\begin{figure}[hb!]
  \centering
  \begin{tikzpicture}
    \tikzumlset{font=\tiny}

    \umlclass{NumberT}{
      \# width : const uint64\_t
    }{
      \umlvirt{+ getType() : llvm::Type} \\ 
      \umlvirt{+ getBitWidth() : uint64\_t}
    }
    \umlclass[y=-3]{GroupT}{
      \# modulus : const llvm::APInt
    }{
      + getModulus() : llvm::APInt \\
      + getModulusConstant() : llvm::ConstantInt
    }
    \umlinherit{NumberT}{GroupT}
  \end{tikzpicture}
  \caption{Type system UML}
  \label{fig:type_system}
\end{figure}

NumberT represents any general number type that can occur (types Int
and Z), while GroupT represents group types (types Zmod+ and Zmod*). The
getType() method returns the backing type in the LLVM IR (IntegerType
of the appropriate length). The modulus of the GroupT is stored as an
LLVM arbitrary precision integer (llvm::APInt) and it can be fetched
by using the getter getModulus(). getModulusConstant() is a helper
method that wraps it in a ConstantInt which LLVM can then use for
constant folding.

\subsection{Type Inference}

The easiest approach for determining a resulting type from two
operands is to use double dispatch and code each of the resulting
functions.  There were some attempts at bringing multiple dispatch to
C++ but this has still not been realized \cite{c++_multi_methods}.

A common way to simulate it in C++ is to use a visitor pattern. The
base interface or the base class defines accept methods. The visitor
then calls each of the classes dispatching itself as a parameter. Here
is how it is done with GroupT and NumberT:

\begin{lstlisting}[language=C++]
class NumberT {
  ...
  virtual NumberT *addWithSubFrom(const NumberT *first);
  ...
  virtual NumberT *operator+(const NumberT &other) const {
    return other.addWithSubFrom(this);
  }
};

class GroupT : public NumberT {
  ...
};
\end{lstlisting}

Here the addWithSubFrom method is the \emph{accept method}.  The same
was done for each of the operators. When the compiler encouters a + b
where a and b have NumberT as a base class, it will call the
\textbf{operator+}. This call happens through a \emph{vtable} so the
\emph{this} pointer always points to the accurate type for the first
operand. By calling the addWithSubFrom method, another \emph{vtable}
dispatch happens and within the addWithSubFrom \textbf{this} points to
the accurate type for the second operand \cite{Eckel}. Since both of
the operands are now correctly resolved it remains to return the
resulting type of the operation. Extending the type inference simply
involves writing a function for each combination of the operand
types. This is somewhat easier than using Run Time Type Information
and writing an if-then-else or similar for each of the cases.

Since GroupT derives from NumberT the operator calls will remain this
way unless overridden. The accept methods will need to be overridden
as they provide the custom logic for each of the combinations.

The classes NumberT and GroupT also define methods for creating an
LLVM instruction for addition, subtraction, multiplication and
exponentiation. These functions act as adapters to the appropriate
LLVM IR instructions and make the process of code-generation
uniform. Here is an excerpt from the code generation:
\begin{lstlisting}[language=C++, morekeywords=expr]
expr[const char *id] returns [Value *value, NumberT *type]
	:	...
	|	^('+' lhs=expr[$id] rhs=expr[$id]) {
                  $type = *$lhs.type + *$rhs.type;
                  $value = $type->createAdd($lhs.value, $rhs.value);
                }
	|	...
\end{lstlisting}
Since the \textbf{type} possesses all the information about the type
(modulus, interval\ldots) only the operands need to be passed in.

\subsection{Variable Scoping}

A hierarchical based approach to scoping is used meaning that each
level of scoping allows access to all the variables from the previous
scope. The current scope thus includes variables from the previous scope as
well as local variables.

\begin{lstlisting}[language=C++]
  struct Variable {
    bool variable;
    NumberT *type;
    Value *value;
  };

  static stack< map<const char*, Variable, cmp_str>* > Vars;
\end{lstlisting}

Entering a block definition or a function definition generates a new
level of scope and a copy of all the variables from the previous scope
is pushed on the top of the stack. Likewise, leaving a block
definition or a function definition removes all the variables from the
previous scope by popping the top of the stack. That way, local scope
is always accessible by peeking the top of the stack and local
variables are added and found via this indirection.

\section{Optimization Passes}

Optimization passes search the generated LLVM IR for specific use
patterns and modify them accordingly with the optimization they are
supposed to perform. LLVM, as a compiler infrastructure framework,
already provides the common ones such as dead code elimination and we
merely complement them with other optimization passes that are valid
for our specific model. For example, Store/Load will search for a Load
instruction following a Store instruction with the same memory
location and remove the redundant Load instruction.

\subsection{Store/Load}

The instructions of the block are iterated in order searching for
Store instructions. When a Store instruction is found, another search
is started from that point searching for a Load instruction loading
from the same memory address. For each such Load instruction found,
all the instructions that the Load instruction dominates (that use the
loaded value) are modified to use the value the Store instruction was
supposed to store.

\begin{lstlisting}[language=C++]
for(BasicBlock::iterator I = BB.begin(); I != BB.end(); I++) {
  if(StoreInst *SI = dyn_cast<StoreInst>(I)) {
    Value *destination = SI->getPointerOperand();

    BasicBlock::iterator J(I);

    for(J++; J != BB.end(); J++) {
      if(LoadInst *LI = dyn_cast<LoadInst>(J)) {
        if(LI->getPointerOperand() == destination) {
	  LI->replaceAllUsesWith(SI->getOperand(0));
	  J--;
	  LI->removeFromParent();
	  changed = true;
        }
      }
    }
  }
}
\end{lstlisting}

This optimization, aside from the obvious performance optimization,
has the goal of ensuring a trivial CFG per round. As discussed before,
memory operations impose an inherent ordering due to only one
operation allowed within a single clock cycle. The optimization
presented here removes the need to load from the same memory location
more than once and as such there is no imposed ordered but the DFG
constrained one.

\section{Back-ends}
\label{sec:back_ends}

Two back-ends have been developed targeting the two corners of the
HW-SW co-design spectrum. A purely software implementation is provided
via a C back-end that uses GMP as its multi-precision arithmetic
library and a purely hardware implementation is provided via GEZEL.
Little attention was given to automated implementations in the middle
of the spectrum as they require solving complex optimization problems
such as scheduling.

\subsection{C+GMP Back-end}
\label{subsec:c_back_end}

The C+GMP Back-end implements the operations sequentially one after
the other. Each round is implemented as a separate function with the
output and input parameters being the arguments of the function. The
intermediate results are kept in local variables of the function with
the allocation and de-allocation simulating stack allocation and
de-allocation.

Below is an example of the commitment round within the Schnorr
protocol:
\begin{lstlisting}[language=C]
void Round1(mpz_t Out0) {
  mpz_t _r_1, _t_1;
  mpz_init(_r_1);
  mpz_init(_t_1);

  mpz_urandomm(_r_1, rstate, _mpz_11);
  mpz_set(g_r_1, _r_1);
  mpz_powm(_t_1, _mpz_3, _r_1, _mpz_23);
  mpz_set(Out0, _t_1);

  mpz_clear(_r_1);
  mpz_clear(_t_1);
}
\end{lstlisting}
Variables are named the same as they are in the input PIL file with
global variables being prefixed with g. As the GMP library does not
allow to input constants at operation invocation, they need to be
prepared beforehand. They are declared as global variables with the
prefix \_mpz\_ and the respective constant. The special \textbf{init}
function initializes these constants along with global variables and
the random number generator:
\begin{lstlisting}[language=C]
void init() {
  mpz_init(g_r_1);
  mpz_init(g_s_1);
  
  mpz_init_set_str(_mpz_3, "3", 10);
  mpz_init_set_str(_mpz_4, "4", 10);
  mpz_init_set_str(_mpz_11, "11", 10);
  mpz_init_set_str(_mpz_23, "23", 10);
  
  gmp_randinit_default(rstate);
}
\end{lstlisting}
And the special \textbf{clear} function clears them:
\begin{lstlisting}[language=C]
void clear() {
  mpz_clear(g_r_1);
  mpz_clear(g_s_1);
  
  mpz_clear(_mpz_3);
  mpz_clear(_mpz_4);
  mpz_clear(_mpz_11);
  mpz_clear(_mpz_23);
}
\end{lstlisting}

\subsection{GEZEL Back-end}
\label{subsec:gezel_back_end}

The GEZEL Back-end implements one GEZEL datapath per round (Figure
\ref{fig:gezel_backend}). The CFG is trivial and there is no imposed
operation ordering but the DFG constrained one. The hardware
implementation is thus purely combinatorial and each invocation of
addition, multiplication, exponentiation requires a new instantiation
of an adder, multiplier, exponentiator, respectively.

\begin{figure}[hb!]
  \centering
  \begin{tikzpicture}[>=stealth]
    \node[language, inner sep=0.5cm](round0){Round0};
    \node[language, inner sep=0.5cm](round1)[below=of round0]{Round1};
    \node[language, inner sep=0.5cm](round2)[below=of round1]{Round2};

    \node[language, inner sep=0.5cm](regs)[above=of round0]{Registers};

    \node[language, inner sep=0.5cm](mux_in)[left=2cm of round1]{Input bus};

    \node[language, inner sep=0.5cm](mux_out)[right=2cm of round1]{Output multiplexer};

    \draw[->](round0.east) -- (mux_out.west);
    \draw[->](round1.east) -- (mux_out.west);
    \draw[->](round2.east) -- (mux_out.west);
    \draw[->](mux_in.east) -- (round0.west);
    \draw[->](mux_in.east) -- (round1.west);
    \draw[->](mux_in.east) -- (round2.west);
    \draw[->](regs.west) -- (mux_in.north |- regs.west) -- (mux_in.north);
    \draw[->](mux_out.north) -- (mux_out.north |- regs.east) -- (regs.east);
  \end{tikzpicture}
  \caption{Generated GEZEL model of Schnorr's protocol}
  \label{fig:gezel_backend}
\end{figure}

Below is an example from the commitment round of the Schnorr Protocol:

\begin{lstlisting}[language=GEZEL]
dp round1(in  r_r_1_i : ns(160); out r_r_1_o : ns(160);
          in  r_s_1_i : ns(160); out r_s_1_o : ns(160);
          out _t_1 : ns(1024)) {
          
  sig s_r_1 : ns(1024);
  sig s_t_1 : ns(1024);

  use random1(11, s_r_1);
  use modexp1(3, s_r_1, 23, s_t_1);
  
  always {
    r_r_1_o = s_r_1;
    r_s_1_o = r_s_1_i;

    _t_1 = s_t_1;
  }
}
\end{lstlisting}

The memory accesses are converted to register accesses and each
datapath gets access to each of the registers. Each register is
prefixed with r and suffixed with i if referring to the input from the
register or o if referring to the output from the register. The
internal signals within a datapath are prefixed with s.

Auxiliary signals represent intermediate values and register accesses
and are declared first followed by the block instances. Constant
values are passed as such and represent a programmable interconnect
connecting either to ground or supply. Lastly, the \textbf{always}
block manages the wire cross-connections. Values to be stored in
registers are either connected to a controlling signal or in a loop
from the current register output. Register controlling outputs are
propagated to the main data path instantiating the party:

\begin{lstlisting}[language=GEZEL]
dp prover {
  reg r_r_1 : ns(160);
  reg r_s_1 : ns(160);
  
  ...
  
  sig r_r_1_o_0, r_r_1_o_1, r_r_1_o_2 : ns(160);
  sig r_s_1_o_0, r_s_1_o_1, r_s_1_o_2 : ns(160);
  
  ...
  
  use Round0(r_r_1, r_r_1_o_0, r_s_1, r_s_1_o_0);
  use Round1(r_r_1, r_r_1_o_1, r_s_1, r_s_1_o_1, _t_1);
  use Round2(r_r_1, r_r_1_o_2, r_s_1, r_s_1_o_2, _c, _s_1);

  ...
\end{lstlisting}

Logic is added that multiplexes these values (r\_r\_1\_o\_x,
r\_s\_1\_o\_x) to the respective register such that only the current
executing round can modify the value in the register.

%%% Local Variables: 
%%% TeX-PDF-mode: t
%%% TeX-master: "thesis"
%%% End: 
